import streamlit as st
from PIL import Image

st.set_page_config(page_title="Probabilistic DCA", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Banner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
banner_col1, banner_col2 = st.columns([1, 2])
with banner_col1:
    logo = Image.open("images/dca_workflow_2.png")
    st.image(logo, use_container_width=True)

with banner_col2:
    st.title("ğŸ“ˆ Probabilistic Decline Curve Analysis (DCA)")
    st.markdown(
        """
        **Automate** uncertaintyâ€‘aware oilâ€‘production forecasting based on SPEâ€‘194503â€‘PAâ€™s Monteâ€‘Carlo+multiâ€‘model approach.
        """
    )
    st.markdown(
        """
        **Key features:**  
        - ğŸ”„  Staged pipeline: data â†’ sampling â†’ fitting â†’ EUR  
        - ğŸ§   Multiâ€‘model (ARPS, SEM, CRM, LGM)  
        - ğŸ“Š  Realâ€‘time UI & exportable CSV/PDF  
        """
    )

    # â”€â”€â”€â”€â”€ Tabs under Key Features â”€â”€â”€â”€â”€
    tabs = st.tabs([
        "ğŸ¯ Project Goals",
        "ğŸ§ª Methodology",
        "ğŸ“š Models",
        "âš™ï¸ Tech Details"
    ])

    with tabs[0]:  # Project Goals
        st.markdown(
            """
            - **Integrate model uncertainty** rather than a single â€œbestâ€ model. By treating each modelâ€™s goodnessâ€‘ofâ€‘fit as a probability, you weight forecasts by how likely each model truly represents the underlying physics. 
            - **Propagate measurement & model uncertainty** into production forecasts via Monte Carlo + Bayesian updating. This yields a single probabilistic forecast that inherently accounts for errors in the data and ambiguity in model choice.  
            - **Mitigate over/underâ€‘estimations** that arises when relying on one model. The combined multiâ€‘model forecast reduces the risk of â€œprecisely wrongâ€ point estimates by generating a â€œvaguely rightâ€ distribution.  
            - **Validate on field data**. Show that (a) no single model dominates for all wells, and (b) adding more data tightens uncertainty and improves hindcast performance.  
            """
        )

    with tabs[1]:  # Methodology
        st.markdown(
            """
            1. **Estimate measurement errors**    
                - Use LOESS (â€œrlowessâ€) + rollingâ€‘window SD to derive pointâ€‘wise standard deviations (râ‚–) for each rate datapoint
            2. **Monte Carlo sampling**
               - At each time step, draw N synthetic rate values from ğ’©(qÌ‚,Â rk), then sort across samples to preserve marginal distributions without bias.
            3. **History matching via (MLE)**  
               - For each sampled dataset, fit each candidate model by minimizing weighted SSE, i.e. Lâ‚˜â‚—â‚‘(x)=âˆ‘(q_modelâˆ’q_data)Â²/rkÂ².
            4. **Bayesian model probabilities**   
               - Compute each modelâ€™s posterior probability P(mÂ |Â data) âˆ exp(â€“Â½Â Lâ‚˜â‚—â‚‘) normalized across models.
            5. **Forecast aggregation**
               - Weight each modelâ€™s forecast by its marginal probability and combine to get a single probabilistic forecast (MMâ€‘P) that integrates both intrinsic and model uncertainty. 
            6. **Analyze & report**
               - Extract percentiles (P10/P50/P90), means, and full EUR distributions. Validate via hindcasts on unseen data and apply to field examples.    
            """
        )

    with tabs[2]:  # Models
        st.markdown(
            """
            **These four models provide a balance of empirical simplicity and physicsâ€‘based insightâ€”more can be added as needed.**
            - **Arps (exp/hyp)**:   
                qâ‚œ = qâ‚€(1 + bâ€¯Dáµ¢â€¯t)^(-1/b), 0â‰¤b<1      
                Classic, empirical, fast; may misâ€‘represent multiâ€‘regime fracture flow â€‹    
            
            - **Stretched Exponential (SEM):**  
                qâ‚œ = qâ‚€â€¯exp[âˆ’(t/s)^n]     
                Captures a distribution of characteristic times; fatâ€‘tailed declines   
            
            - **Logistic Growth (LGM):**    
                qâ‚œ = aâ€¯Kâ€¯t^(gâˆ’1)/(a + t^g)^2     
                Sigmoidal, directly estimates carrying capacity (EUR) K   
            - **Pan CRM:**    
                qâ‚œ = Î”P/(bâˆšt + Jâ‚)Â·exp[âˆ’(2â€¯bâˆšt + Jâ‚â€¯t)/(câ‚œâ€¯Vâ‚š)]     
                Physicsâ€‘based, handles linearâ€‘toâ€‘boundary flow; skip first 10Â days to avoid singularity   
              
            """
        )

    with tabs[3]:  # Tech Details (unchanged)
        st.markdown("_View package structure, config, and extended technical notes below._")
        with st.expander("Folder structure & config overview", expanded=False):
            st.code(
                """
project_root/
â”œâ”€ app/pages/1_Pipeline_Run.py
â”œâ”€ app/pages/2_Generate_Report.py
â”œâ”€ images/dca_workflow_2.png
â”œâ”€ src/probabilistic_dca/
â”‚  â”œâ”€ my_dca_models/
â”‚  â”œâ”€ config.py
â”‚  â””â”€ logging_setup.py
â””â”€ tests/
                """, language="bash"
            )
            st.markdown(
                """
                - **config.py** holds defaults (n_inits, thresholdsâ€¦)  
                - **logging_setup** for structured logs  
                - **tests/** cover data & fitting modules  
                """
            )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("ğŸš€ Jump to")
st.sidebar.markdown("- **Pipeline Run**")  
st.sidebar.markdown("- **Generate Report**")
st.sidebar.markdown("---")
st.sidebar.markdown("By: Alexis Ortega")
st.sidebar.markdown("[ğŸ”— Source on GitHub](https://github.com/alexort74/probabilistic_dca)")


